require("dotenv").config();
const cors = require("cors");
const express = require("express");
const multer = require("multer");
const fs = require("fs");
const PORT = process.env.PORT || 3000

const textToSpeech = require("@google-cloud/text-to-speech");
const speech = require("@google-cloud/speech").v1;


const { GoogleGenerativeAI } = require("@google/generative-ai");

const app = express();
const upload = multer({ dest: "/tmp/uploads/" });
if (!fs.existsSync("/tmp/uploads")) {
  fs.mkdirSync("/tmp/uploads", { recursive: true });
}

app.use(express.json());
app.use(cors({
  origin: "*",
  methods: ["GET", "POST"],
  allowedHeaders: ["Content-Type"],
}));
app.get("/", (req, res) => {
  res.status(200).json({
    status: "OK",
    message: "Backend is live ðŸš€",
  }); 
});

const googleCredentials = JSON.parse(
  process.env.GOOGLE_SERVICE_ACCOUNT_JSON
);


const ttsClient = new textToSpeech.TextToSpeechClient({
  credentials: googleCredentials,
  projectId: process.env.GOOGLE_CLOUD_PROJECT_ID,
});

const sttClient = new speech.SpeechClient({
  credentials: googleCredentials,
  projectId: process.env.GOOGLE_CLOUD_PROJECT_ID,
});

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);



// ---------- LANGUAGE DETECTION ----------
function detectLanguage(text) {
  const hindiHints = [
    "à¤¹à¥ˆ", "à¤¥à¤¾", "à¤•à¤¿à¤¯à¤¾", "à¤¨à¤¹à¥€", "à¤•à¥à¤¯à¥‹à¤‚", "à¤®à¥ˆà¤‚", "à¤®à¥‡à¤°à¤¾",
    "à¤®à¥à¤à¥‡", "à¤®à¥ˆà¤‚à¤¨à¥‡", "à¤…à¤ªà¤¨à¥‡", "à¤šà¤¾à¤¹à¤¿à¤", "à¤¦à¥‹à¤¸à¥à¤¤", "à¤†à¤—à¥‡"
  ];
  const lower = text.toLowerCase();
  const score = hindiHints.filter(w => lower.includes(w)).length;
  return score >= 2 ? "hi" : "en";
}



// ---------- SPEECH TO TEXT ----------
async function speechToText(audioPath) {
  return new Promise((resolve) => {
    const audioStream = fs.createReadStream(audioPath);

    const request = {
      config: {
        encoding: "WEBM_OPUS",
        sampleRateHertz: 48000,
        languageCode: "en-IN",
        alternativeLanguageCodes: ["hi-IN"],
        enableAutomaticPunctuation: true,
      },
      interimResults: false,
    };

    let transcript = "";

    const recognizeStream = sttClient
      .streamingRecognize(request)
      .on("error", err => {
        console.error("Streaming STT error:", err);
        resolve({ text: "", lang: "en" });
      })
      .on("data", data => {
        if (data.results[0]?.alternatives[0]) {
          transcript += data.results[0].alternatives[0].transcript;
        }
      })
      .on("end", () => {
        if (!transcript) {
          resolve({ text: "", lang: "en" });
        } else {
          resolve({
            text: transcript,
            lang: detectLanguage(transcript),
          });
        }
      });

    audioStream.pipe(recognizeStream);
  });
}


async function chatWithAI(userText, lang, memory) {
  if (!userText) {
    return lang === "hi"
      ? "à¤•à¥à¤·à¤®à¤¾ à¤•à¤°à¥‡à¤‚, à¤®à¥à¤à¥‡ à¤•à¥à¤› à¤¸à¥à¤¨à¤¾à¤ˆ à¤¨à¤¹à¥€à¤‚ à¤¦à¤¿à¤¯à¤¾à¥¤"
      : "Sorry, I did not catch that.";
  }

  const model = genAI.getGenerativeModel({
    model: "gemini-3-flash-preview",
  });

  // Build previous conversation context
  let contextText = "";
  if (memory?.history?.length) {
    contextText = memory.history
      .map(m =>
        m.role === "user"
          ? `User: ${m.text}`
          : `NyaySaathi: ${m.text}`
      )
      .join("\n");
  }

  const systemPrompt =
    (lang === "hi"
      ? "à¤†à¤ª NyaySaathi à¤¹à¥ˆà¤‚, à¤à¤• à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤•à¤¾à¤¨à¥‚à¤¨à¥€ à¤¸à¤¹à¤¾à¤¯à¤¤à¤¾ AIà¥¤ à¤†à¤ª à¤à¤• à¤¯à¥‹à¤—à¥à¤¯ à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤µà¤•à¥€à¤² à¤•à¥€ à¤¤à¤°à¤¹ à¤¬à¤¾à¤¤ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤ à¤†à¤ªà¤•à¥€ à¤­à¤¾à¤·à¤¾ à¤¶à¤¾à¤‚à¤¤, à¤¸à¤®à¥à¤®à¤¾à¤¨à¤œà¤¨à¤•, à¤¸à¤‚à¤µà¥‡à¤¦à¤¨à¤¶à¥€à¤² à¤”à¤° à¤ªà¥‡à¤¶à¥‡à¤µà¤° à¤¹à¥‹à¤¤à¥€ à¤¹à¥ˆ à¤”à¤° à¤†à¤ª à¤•à¤¾à¤¨à¥‚à¤¨à¥€ à¤¬à¤¾à¤¤à¥‹à¤‚ à¤•à¥‹ à¤†à¤® à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤¸à¤°à¤² à¤µ à¤¸à¥à¤ªà¤·à¥à¤Ÿ à¤¶à¤¬à¥à¤¦à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¸à¤®à¤à¤¾à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤ à¤†à¤ª à¤¹à¤®à¥‡à¤¶à¤¾ à¤ªà¤°à¥à¤¯à¤¾à¤ªà¥à¤¤ à¤µà¤¿à¤¸à¥à¤¤à¤¾à¤° à¤¸à¥‡ à¤‰à¤¤à¥à¤¤à¤° à¤¦à¥‡à¤¤à¥‡ à¤¹à¥ˆà¤‚, à¤¬à¤¹à¥à¤¤ à¤›à¥‹à¤Ÿà¥‡ à¤¯à¤¾ à¤à¤• à¤ªà¤‚à¤•à¥à¤¤à¤¿ à¤•à¥‡ à¤‰à¤¤à¥à¤¤à¤° à¤¨à¤¹à¥€à¤‚ à¤¦à¥‡à¤¤à¥‡ à¤”à¤° à¤ªà¥à¤°à¤¤à¥à¤¯à¥‡à¤• à¤‰à¤¤à¥à¤¤à¤° à¤•à¤ˆ à¤›à¥‹à¤Ÿà¥‡ à¤…à¤¨à¥à¤šà¥à¤›à¥‡à¤¦à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¦à¥‡à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤¤à¤¾à¤•à¤¿ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤¸à¥à¤¥à¤¿à¤¤à¤¿ à¤•à¥‹ à¤…à¤šà¥à¤›à¥€ à¤¤à¤°à¤¹ à¤¸à¤®à¤ à¤¸à¤•à¥‡à¥¤ à¤†à¤ª à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤•à¤¾à¤¨à¥‚à¤¨ à¤•à¥‡ à¤…à¤‚à¤¤à¤°à¥à¤—à¤¤ à¤•à¤¾à¤¨à¥‚à¤¨à¥€ à¤…à¤§à¤¿à¤•à¤¾à¤°à¥‹à¤‚, à¤‰à¤ªà¤²à¤¬à¥à¤§ à¤‰à¤ªà¤¾à¤¯à¥‹à¤‚ à¤”à¤° à¤¸à¤¹à¥€ à¤•à¤¾à¤¨à¥‚à¤¨à¥€ à¤ªà¥à¤°à¤•à¥à¤°à¤¿à¤¯à¤¾ à¤•à¥‹ à¤¸à¤®à¤à¤¾à¤¨à¥‡ à¤®à¥‡à¤‚ à¤®à¤¦à¤¦ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚, à¤•à¤¿à¤¸à¥€ à¤ªà¤°à¤¿à¤£à¤¾à¤® à¤•à¥€ à¤—à¤¾à¤°à¤‚à¤Ÿà¥€ à¤¨à¤¹à¥€à¤‚ à¤¦à¥‡à¤¤à¥‡, à¤•à¥‹à¤ˆ à¤…à¤µà¥ˆà¤§ à¤¸à¤²à¤¾à¤¹ à¤¨à¤¹à¥€à¤‚ à¤¦à¥‡à¤¤à¥‡ à¤”à¤° à¤Ÿà¤•à¤°à¤¾à¤µ à¤¯à¤¾ à¤¹à¤¿à¤‚à¤¸à¤¾ à¤•à¥‹ à¤ªà¥à¤°à¥‹à¤¤à¥à¤¸à¤¾à¤¹à¤¿à¤¤ à¤¨à¤¹à¥€à¤‚ à¤•à¤°à¤¤à¥‡à¥¤ à¤†à¤ª à¤ªà¤¹à¤²à¥‡ à¤•à¤¾à¤¨à¥‚à¤¨à¥€ à¤¸à¥à¤¥à¤¿à¤¤à¤¿ à¤¸à¥à¤ªà¤·à¥à¤Ÿ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚, à¤«à¤¿à¤° à¤µà¥à¤¯à¤¾à¤µà¤¹à¤¾à¤°à¤¿à¤• à¤•à¤¦à¤® à¤¬à¤¤à¤¾à¤¤à¥‡ à¤¹à¥ˆà¤‚, à¤«à¤¿à¤° à¤†à¤µà¤¶à¥à¤¯à¤• à¤¸à¤¬à¥‚à¤¤ à¤¯à¤¾ à¤¦à¤¸à¥à¤¤à¤¾à¤µà¥‡à¤œà¤¼ à¤¸à¤®à¤à¤¾à¤¤à¥‡ à¤¹à¥ˆà¤‚, à¤«à¤¿à¤° à¤­à¤¾à¤°à¤¤ à¤•à¥‡ à¤¸à¤®à¤¾à¤¨ à¤®à¤¾à¤®à¤²à¥‹à¤‚ à¤•à¥‡ à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤‰à¤¦à¤¾à¤¹à¤°à¤£ à¤¦à¥‡à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤”à¤° à¤…à¤‚à¤¤ à¤®à¥‡à¤‚ à¤¬à¤¤à¤¾à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤•à¤¿ à¤•à¤¬ à¤µà¤•à¥€à¤², à¤ªà¥à¤²à¤¿à¤¸, à¤¸à¥à¤•à¥‚à¤² à¤ªà¥à¤°à¤¬à¤‚à¤§à¤¨, à¤¨à¤¿à¤¯à¥‹à¤•à¥à¤¤à¤¾ à¤¯à¤¾ à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤ªà¥à¤°à¤¾à¤§à¤¿à¤•à¤°à¤£ à¤¸à¥‡ à¤¸à¤‚à¤ªà¤°à¥à¤• à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¤¿à¤à¥¤ à¤†à¤ª à¤•à¥‡à¤µà¤² à¤¸à¤¾à¤¦à¤¾ à¤ªà¤¾à¤  à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚, à¤¬à¥à¤²à¥‡à¤Ÿ à¤ªà¥‰à¤‡à¤‚à¤Ÿ, à¤¨à¤‚à¤¬à¤°à¤¿à¤‚à¤—, à¤šà¤¿à¤¨à¥à¤¹, à¤®à¤¾à¤°à¥à¤•à¤¡à¤¾à¤‰à¤¨ à¤¯à¤¾ à¤‡à¤®à¥‹à¤œà¥€ à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤¨à¤¹à¥€à¤‚ à¤•à¤°à¤¤à¥‡ à¤”à¤° à¤µà¥‰à¤¯à¤¸ à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ à¤•à¥‡ à¤²à¤¿à¤ à¤‰à¤ªà¤¯à¥à¤•à¥à¤¤ à¤›à¥‹à¤Ÿà¥‡ à¤…à¤¨à¥à¤šà¥à¤›à¥‡à¤¦à¥‹à¤‚ à¤®à¥‡à¤‚ à¤²à¤¿à¤–à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤ à¤¯à¤¦à¤¿ à¤®à¤¾à¤®à¤²à¤¾ à¤¨à¤¾à¤¬à¤¾à¤²à¤¿à¤—à¥‹à¤‚, à¤®à¤¹à¤¿à¤²à¤¾à¤“à¤‚, à¤‰à¤¤à¥à¤ªà¥€à¤¡à¤¼à¤¨, à¤¬à¥à¤²à¥€à¤‡à¤‚à¤—, à¤¶à¥‹à¤·à¤£ à¤¯à¤¾ à¤¸à¥à¤°à¤•à¥à¤·à¤¾ à¤¸à¥‡ à¤œà¥à¤¡à¤¼à¤¾ à¤¹à¥‹ à¤¤à¥‹ à¤†à¤ª à¤…à¤¤à¤¿à¤°à¤¿à¤•à¥à¤¤ à¤¸à¤‚à¤µà¥‡à¤¦à¤¨à¤¶à¥€à¤²à¤¤à¤¾ à¤”à¤° à¤¸à¤¹à¤¾à¤¨à¥à¤­à¥‚à¤¤à¤¿ à¤¦à¤¿à¤–à¤¾à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤”à¤° à¤¯à¤¦à¤¿ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤…à¤ªà¤°à¥à¤¯à¤¾à¤ªà¥à¤¤ à¤¹à¥‹ à¤¤à¥‹ à¤µà¤¿à¤¨à¤®à¥à¤°à¤¤à¤¾ à¤¸à¥‡ à¤•à¥‡à¤µà¤² à¤ªà¥à¤°à¤¾à¤¸à¤‚à¤—à¤¿à¤• à¤…à¤¨à¥à¤µà¤°à¥à¤¤à¥€ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤ªà¥‚à¤›à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤"

      : "You are NyaySaathi, an Indian legal assistance AI.\n\nYou speak like a qualified Indian lawyer. Your tone is calm, respectful, empathetic, and professional. You explain legal concepts clearly to non-lawyers.\n\nYou must give sufficiently detailed explanations. Do not give one-line or very short answers. Each response should normally be several short paragraphs so the user clearly understands the situation.\n\nYou help users understand their legal rights, available remedies, and correct legal procedure under Indian law. You do not promise outcomes. You do not give illegal advice. You do not encourage confrontation or violence.\n\nYou always explain the legal position first in clear terms. Then explain what the user can do in practical steps. Then explain what kind of evidence or documents are usually important. Then give one or two brief real-world examples of similar situations that have occurred in India, described in general terms. Then explain when it is necessary to approach a lawyer, police, school authority, employer, or government body.\n\nUse plain text only. Do not use asterisks, bullet points, numbering, markdown, emojis, or special formatting. Use short paragraphs suitable for voice output, but do not over-summarize.\n\nIf the matter involves minors, women, harassment, bullying, abuse, or safety, respond with extra care and sensitivity.\n\nIf information is insufficient, politely ask relevant follow-up questions.")
    +
    (memory?.topic
      ? `\n\nThe ongoing legal matter topic is: ${memory.topic}. Continue on the same matter unless the user clearly introduces a new issue.`
      : "");

  const result = await model.generateContent({
    systemInstruction: systemPrompt,
    contents: [
      {
        role: "user",
        parts: [
          {
            text:
              (contextText ? `Previous conversation:\n${contextText}\n\n` : "") +
              (lang === "hi"
                ? `à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤†à¤—à¥‡ à¤•à¤¹ à¤°à¤¹à¤¾ à¤¹à¥ˆ:\n${userText}`
                : `Respond only in English. The user is continuing the same legal matter:\n${userText}`)
          },
        ],
      },
    ],
    generationConfig: {
      maxOutputTokens: 1400,
    },
  });

  return result.response.text();
}



// ---------- TEXT TO SPEECH ----------
async function convertTextToMp3(text, lang) {
  if (!text || !text.trim()) {
    throw new Error("Empty text passed to TTS");
  }

  const MAX_CHUNK_SIZE = 4000;
  const chunks = text.match(new RegExp(`.{1,${MAX_CHUNK_SIZE}}`, "g")) || [text];
  const audioBuffers = [];

  for (const chunk of chunks) {
    const request = {
      input: { text: chunk },
      voice: {
        languageCode: lang === "hi" ? "hi-IN" : "en-IN",
        ssmlGender: "NEUTRAL",
      },
      audioConfig: { audioEncoding: "MP3" },
    };

    const [response] = await ttsClient.synthesizeSpeech(request);
    audioBuffers.push(response.audioContent);
  }

  return Buffer.concat(audioBuffers);
}



app.post("/api/voice", upload.single("audio"), async (req, res) => {
  let audioPath = null;

  try {
    if (!req.file) {
      return res.status(400).json({ error: "No audio file received" });
    }

    audioPath = req.file.path;

    const memory = req.body.memory
      ? JSON.parse(req.body.memory)
      : null;

    const sttResult = await speechToText(audioPath);

    const aiReply = await Promise.race([
    chatWithAI(sttResult.text, sttResult.lang, memory),
    new Promise((_, reject) =>
      setTimeout(() => reject(new Error("AI timeout")), 25000)
    )
    ]);


    const audioBuffer = await convertTextToMp3(
      aiReply,
      sttResult.lang
    );

    if (fs.existsSync(audioPath)) fs.unlinkSync(audioPath);

    
    res.json({
      text: aiReply,
      lang: sttResult.lang,
      audio: audioBuffer.toString("base64")
    });
    console.log(sttResult)
  } catch (err) {
    console.error("Pipeline Error:", err);
    if (audioPath && fs.existsSync(audioPath)) fs.unlinkSync(audioPath);
    res.status(500).json({ error: "Voice processing failed." });
  }
});


app.listen(PORT, () => {
  console.log(`Server running on PORT ${PORT}`);
});
